{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_do.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doppelgangerlynx/digit-recognizer/blob/master/MNIST_do.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z47Kx1O9btgV",
        "colab_type": "text"
      },
      "source": [
        "#1. Import dependencies#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGdzLyjvbSlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import pprint\n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ksZ8e0PbyNE",
        "colab_type": "text"
      },
      "source": [
        "#2.Test TPUs#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woC_WjaCb1uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "devices=None\n",
        "try:\n",
        "    device_name = os.environ['COLAB_TPU_ADDR']\n",
        "    TPU_addr = 'grpc://' + device_name\n",
        "    print('TPU URL:', TPU_addr)\n",
        "    with tf.Session(TPU_addr) as session:\n",
        "        devices=session.list_devices()\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(devices)\n",
        "except KeyError:\n",
        "    print('TPU not installed in this runtime.')\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1QROAXUdFrN",
        "colab_type": "text"
      },
      "source": [
        "#3.AUTH for google drive#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMdxMGaBdMYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir(\"/content/gdrive/My Drive/MNIST_custom\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhiSpyQLeXU4",
        "colab_type": "text"
      },
      "source": [
        "#4. Reading from CSVs#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eso89iL9eEyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = np.genfromtxt('train.csv',delimiter=',')[1:]\n",
        "print(training_set.shape)\n",
        "y_train=training_set[:,0]\n",
        "x_train\\\n",
        "    =training_set[:, 1:].reshape((training_set.shape[0], 28, 28, 1)).astype('float32')/255.0\n",
        "print(\"x_train.shape\",x_train.shape)\n",
        "print(\"y_train.shape\",y_train.shape)\n",
        "\n",
        "\n",
        "testing_set = np.genfromtxt('test.csv',delimiter=',')[1:].astype('float32')\n",
        "print(testing_set.shape)\n",
        "# y_test=testing_set[:,0]\n",
        "x_test=testing_set[:,:].reshape((testing_set.shape[0],28, 28, 1)).astype('float32')/255.0\n",
        "print(\"x_test.shape\",x_test.shape)\n",
        "# print(y_test.shape)\n",
        "\n",
        "plt.gray()\n",
        "\n",
        "plt.title(str(y_train[0]) + ' shown')\n",
        "sample_plot = plt.imshow(x_train[0][:, :, 0])\n",
        "# print(y_train[0],'shown')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbMfBYKVnyO0",
        "colab_type": "text"
      },
      "source": [
        "#5. Build the MNIST CNN#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPf213ENn6P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =tf.keras.models.Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28,1)),\n",
        "    # Note: the first layer has to be given the input shape. After that is very automatic.\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(.2),\n",
        "    \n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(.2),\n",
        "    \n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(.25),\n",
        "    Dense(10, activation='softmax')    \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_LQ1JvYqHIg",
        "colab_type": "text"
      },
      "source": [
        "#6.Keras model to TPU: conversion#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cPpaEP0qSQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_addr)\n",
        "    )\n",
        ")\n",
        "tpu_model.compile(\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "# generator: A generator or an instance of Sequence (keras.utils.Sequence) object in order to avoid duplicate data when using multiprocessing. The output of the generator must be either\n",
        "\n",
        "# a tuple (inputs, targets)\n",
        "# a tuple (inputs, targets, sample_weights).\n",
        "def train_gen(batch_size):\n",
        "    # the reason for using the generator function is because it does not allocate new function stacks, thus efficient\n",
        "    while True:\n",
        "        # First, we choose the first random starting index for the random batch\n",
        "        offset = np.random.randint(0, x_train.shape[0] - batch_size)\n",
        "        yield x_train[offset:offset+batch_size], y_train[offset:offset+batch_size]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeoqSSIFs0Jr",
        "colab_type": "text"
      },
      "source": [
        "#7. Train the model and time it#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU_twFp5s_pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "history = tpu_model.fit_generator(\n",
        "    train_gen(128),\n",
        "    epochs=30,\n",
        "    steps_per_epoch=100\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fkuR9Gatqi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(tpu_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3TqS2Q9FqtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT7NM43MFjL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def plot_hist(train_loss, train_acc, test_loss, test_acc):\n",
        "#   fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "  \n",
        "#   ax1.plot(train_loss, label='train loss')\n",
        "#   ax1.plot(test_loss, label='test loss')\n",
        "#   ax1.set_xlabel('Epochs')\n",
        "#   ax1.set_ylabel('Loss')\n",
        "#   ax1.set_title('Train & Test Loss')\n",
        "#   ax1.legend()\n",
        "  \n",
        "  \n",
        "#   ax2.plot(train_acc, label='train acc')\n",
        "#   ax2.plot(test_acc, label='test acc')\n",
        "#   ax2.set_xlabel('Epochs')\n",
        "#   ax2.set_ylabel('Accuracy')\n",
        "#   ax2.set_title('Train & Test Accuracy')\n",
        "#   ax2.legend()\n",
        "    \n",
        "#   plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def plot_hist(train_loss):\n",
        "  fig, (ax1) = plt.subplots(1, 1, figsize=(4, 4))\n",
        "  \n",
        "  ax1.plot(train_loss, label='train loss')\n",
        "  ax1.set_xlabel('Epochs')\n",
        "  ax1.set_ylabel('Loss')\n",
        "  ax1.legend()\n",
        "    \n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls1jZTquFp2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_hist(history.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkGirdLOvA2d",
        "colab_type": "text"
      },
      "source": [
        "#8.Predict the test data#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng1CBQ5WvAWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_prob = tpu_model.predict(x_test)\n",
        "predicted_classes = np.argmax(predicted_prob, axis=1)\n",
        "print(predicted_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l6WsviGxjGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(predicted_classes)\n",
        "\n",
        "print(np.random.randint(predicted_classes.shape[0], size=10).tolist())\n",
        "import time\n",
        "for i in np.random.randint(predicted_classes.shape[0], size=10).tolist():\n",
        "    plt.title(str(predicted_classes[i]) + ' shown')\n",
        "    sample_plot = plt.imshow(x_test[i][:, :, 0])\n",
        "#     time.sleep(0.01)\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itJGuz1c0Ud2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices = np.array(range(1,predicted_classes.shape[0] + 1)).reshape(predicted_classes.shape[0], 1)\n",
        "v_pred = predicted_classes.reshape(predicted_classes.shape[0], 1)\n",
        "print(v_pred)\n",
        "result_df = pd.DataFrame(np.hstack((indices, v_pred)), columns=['ImageId', 'Label'])\n",
        "print(result_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyZ6RZ6p4QyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df.to_csv('submission.csv', encoding='utf-8', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjHTTeSn4mPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HgfOhGyGo_Y",
        "colab_type": "text"
      },
      "source": [
        "# EXTRA: data augmentation#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiosIOPfGs7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CREATE MORE IMAGES VIA DATA AUGMENTATION\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=10,  \n",
        "        zoom_range = 0.10,  \n",
        "        width_shift_range=0.1, \n",
        "        height_shift_range=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8UgQnhwIGHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train again, with the IDG function!\n",
        "%%time\n",
        "history = tpu_model.fit_generator(\n",
        "    datagen.flow(x_train,y_train, batch_size=128),\n",
        "    epochs=20,\n",
        "    steps_per_epoch=x_train.shape[0]//128\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}